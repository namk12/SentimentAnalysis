{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "colab": {
      "name": "Sentiment Analysis HW2.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X367SKcuGf3-"
      },
      "source": [
        "# Using Multinomial Naive Bayes algorithm for sentiment analysis\n",
        "\n",
        "Classify a movie review as 'positive' or 'negative' using Multinomial Naive Bayes.\n",
        "\n",
        "Dataset Source: http://nifty.stanford.edu/2016/manley-urness-movie-review-sentiment/\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAPzayS8MUq1",
        "outputId": "bc30e506-8fd3-4b75-c035-02569d988948"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9mdQulA9Gf4D",
        "outputId": "2124e775-cddf-447f-81e8-a0a06fc8536d"
      },
      "source": [
        "import numpy as np\n",
        "import math\n",
        "\n",
        "# read in train and test files, removing newlines\n",
        "\n",
        "f = open(\"/content/drive/MyDrive/MLAssign2/trainfilex.txt\", \"r\")\n",
        "trainrevs = [line.rstrip('\\n') for line in f]\n",
        "\n",
        "f = open(\"/content/drive/MyDrive/MLAssign2/trainfiley.txt\",\"r\")\n",
        "trainlabels = [line.rstrip('\\n') for line in f]\n",
        "\n",
        "f = open(\"/content/drive/MyDrive/MLAssign2/testfilex.txt\",\"r\")\n",
        "testrevs = [line.rstrip('\\n') for line in f]\n",
        "\n",
        "f = open(\"/content/drive/MyDrive/MLAssign2/testfiley.txt\",\"r\")\n",
        "testlabels = [line.rstrip('\\n') for line in f]\n",
        "\n",
        "print(trainrevs[0:5])\n",
        "print(trainlabels[0:5])\n",
        "\n",
        "print(\"The number of training examples: \", len(trainrevs))\n",
        "print(\"The number of test examples: \", len(testrevs))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[' serious and thoughtful  ', ' with a completely predictable plot  you  ll swear that you  ve seen it all before  even if you  ve never come within a mile of the longest yard  ', ' if there was any doubt that peter o fallon did n t have an original bone in his body  a rumor of angels should dispel it  ', ' i like my christmas movies with more elves and snow and less pimps and ho  s  ', ' a terrifically entertaining specimen of spielbergian sci-fi  ']\n",
            "['1', '0', '0', '0', '1']\n",
            "The number of training examples:  1349\n",
            "The number of test examples:  151\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2N1s9kmoGf4G"
      },
      "source": [
        "###  Computing the vocabulary from the reviews in the training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFo71IAAGf4G"
      },
      "source": [
        "def build_vocab(x):\n",
        "########## TO DO ##########\n",
        "    \n",
        "    lst = []\n",
        "    vocab = []\n",
        "    lst = [i for item in x for i in item.split()]\n",
        "    for i in lst:\n",
        "      if vocab.count(i) == 0:\n",
        "        vocab.append(i)\n",
        "##########\n",
        "    return vocab\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJp5uHycGf4G"
      },
      "source": [
        "### Computing smoothed estimate of P(w|C)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8SvtTlEGf4H"
      },
      "source": [
        "# Input: number n of occurences of w in C, total length N of docs in C, smoothing parameter m, \n",
        "# size of vocabulary vsize\n",
        "# Output: Smoothed estimate of P(w|C)\n",
        "def smooth_estimate(n,N,m,vsize):\n",
        "############# TO DO ###########\n",
        "  V = vsize*m\n",
        "  Deno = N+V\n",
        "  Num = n+m\n",
        "  estimate = Num/Deno\n",
        "\n",
        "########\n",
        "  return estimate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24EvsGOkksdu"
      },
      "source": [
        "  map1 = dict()\n",
        "  map0 = dict()\n",
        "  total_words_1 = 0\n",
        "  total_words_0 = 0\n",
        "  N = 0\n",
        "  for i in range(len(trainrevs)):\n",
        "      temp = trainrevs[i].split()\n",
        "      for word in temp:\n",
        "        if trainlabels[i] == '1':\n",
        "          total_words_1 = total_words_1+1\n",
        "          map1[word] = 1 if word not in map1 else map1[word]+1\n",
        "        else:\n",
        "          total_words_0 = total_words_0+1\n",
        "          map0[word] = 1 if word not in map0 else map0[word]+1\n",
        "\n",
        "N = total_words_1+total_words_0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFJWMz8xGf4I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e99bf604-efca-4cb2-e28d-11db1ea3673a"
      },
      "source": [
        "prob1 = 0\n",
        "prob0 = 0\n",
        "p1 = 0\n",
        "p0 = 0\n",
        "res = []\n",
        "vocab = build_vocab(trainrevs)\n",
        "V = len(vocab)\n",
        "print(V)\n",
        "\n",
        "print(smooth_estimate(map1[\"movie\"],total_words_1,0.2,V))\n",
        "\n",
        "print(smooth_estimate(map0[\"movie\"],total_words_0,0.2,V))\n",
        "\n",
        "for test in testrevs:\n",
        "  \n",
        "  testrevwords = test.split()\n",
        "  \n",
        "  prob1 = math.log(trainlabels.count('1')/len(trainlabels))\n",
        "  prob0 = math.log(trainlabels.count('0')/len(trainlabels))\n",
        "  m = 0.2\n",
        "\n",
        "  for word in testrevwords:\n",
        "    #print(word)\n",
        "    if word in map1:\n",
        "      p1 = smooth_estimate(map1[word],total_words_1,m,V)\n",
        "    else:\n",
        "      p1 = smooth_estimate(0,total_words_1,m,V)\n",
        "\n",
        "    if word in map0:\n",
        "      p0 = smooth_estimate(map0[word],total_words_0,m,V)\n",
        "    else:\n",
        "      p0 = smooth_estimate(0,total_words_0,m,V)\n",
        "\n",
        "    prob1 += math.log(p1)\n",
        "    prob0 += math.log(p0)\n",
        "  \n",
        "  if prob1>prob0:\n",
        "    res.append('1')\n",
        "  else:\n",
        "    res.append('0')\n",
        "\n",
        "prediction_acc = 0\n",
        "\n",
        "for i in range(len(res)):\n",
        "  if res[i] == testlabels[i]:\n",
        "    prediction_acc = prediction_acc+1\n",
        "\n",
        "prediction_acc = prediction_acc/len(res)\n",
        "\n",
        "print(prediction_acc)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5456\n",
            "0.006259309971261341\n",
            "0.009408992332781202\n",
            "0.8543046357615894\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHl1SbU5Gf4I"
      },
      "source": [
        "###  Using sklearn on this dataset and comparing the result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-7N-AfvGf4J"
      },
      "source": [
        "# importing the libraries\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "#vectorizer = CountVectorizer(stop_words='english')\n",
        "vectorizer = CountVectorizer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMsI3kP7Gf4K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "706211f4-34a0-4f10-e1bd-72a060934baa"
      },
      "source": [
        "# Create the vocabulary for our feature transformation\n",
        "vectorizer.fit(trainrevs)\n",
        "\n",
        "# Next we create the feature vectors for the training data\n",
        "X_train = vectorizer.transform(trainrevs).toarray() # code to turn the training reviews into a feature vector\n",
        "X_test = vectorizer.transform(testrevs).toarray() # code to turn the test reviews into a feature vector\n",
        "# create the multinomial naive bayes classifier and fit it to the training data\n",
        "mnb = MultinomialNB()\n",
        "mnb.fit(X_train,trainlabels)\n",
        "\n",
        "# compute the accuracy of the classifier on the test set\n",
        "mnb.score(X_test,testlabels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.847682119205298"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T19UeuOmtAEV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}